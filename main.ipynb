{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies\n",
    "!pip install llama-index --upgrade\n",
    "!pip install llama-index-llms-groq\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-index-llms-huggingface\n",
    "!pip install llama-index-llms-huggingface-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, PromptTemplate, Settings\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "import os\n",
    "\n",
    "llm = Groq(model=\"llama3-70b-8192\", api_key=os.environ.get(\"GROQ_API_KEY1\"))\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Corrected the path to a directory instead of a file\n",
    "de_tools_blog = SimpleDirectoryReader(\"./\", required_exts=[\".pdf\"]).load_data()\n",
    "\n",
    "# print(de_tools_blog)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(de_tools_blog)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "response = query_engine.query(\"How many concepts are used?\")\n",
    "print(response)\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(    \n",
    "   index.as_retriever(),    \n",
    "   memory=memory,    \n",
    "   llm=llm\n",
    ")\n",
    "\n",
    "response = chat_engine.chat(    \n",
    "   \"What is Yulu company all about?\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
